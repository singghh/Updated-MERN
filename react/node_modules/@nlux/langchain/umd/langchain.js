!function(e,t){"object"==typeof exports&&"undefined"!=typeof module?t(exports,require("@nlux/core")):"function"==typeof define&&define.amd?define(["exports","@nlux/core"],t):t((e="undefined"!=typeof globalThis?globalThis:e||self)["@nlux/langchain"]={},e.core)}(this,(function(e,t){"use strict";const r=e=>{const t=/\/.*\/(invoke|stream)$/g.exec(e);if(!t||t.length<2)return;const r=t[1];return"invoke"===r||"stream"===r?r:void 0},s=e=>{const s=r(e.url),o=e.dataTransferMode,n=s?"stream"===s?"stream":"fetch":void 0;const i=n??e.dataTransferMode??a.defaultDataTransferMode;return o&&n&&o!==n&&t.warnOnce(`The data transfer mode provided to LangServe adapter does not match the LangServe runnable URL action. When you provide a runnable URL that ends with '/${s}', the data transfer mode is automatically set to '${n}' and the 'dataTransferMode' option should not be provided or should be set to '${n}'`),i},o=e=>{const t=e.url;return/\/.*\/(invoke|stream)$/g.test(t)?t.replace(/\/(invoke|stream)$/g,""):t},n=e=>{const t=o(e).replace(/\/$/,""),n=(e=>{const t=e.url,o=r(t);return o||("fetch"===s(e)?"invoke":"stream")})(e);return`${t}/${n}`};class a{constructor(e){this.__instanceId=`${this.info.id}-${t.uid()}`,this.__options={...e},this.theDataTransferModeToUse=s(e),this.theHeadersToUse=e.headers||{},this.theUseInputSchemaOptionToUse="boolean"!=typeof e.useInputSchema||e.useInputSchema,this.theEndpointUrlToUse=n(e),this.theRunnableNameToUse=(e=>o(e).replace(/\/$/,"").split("/").pop()||"langserve-runnable")(e),this.theInputSchemaUrlToUse=((e,t)=>{const r=o(e).replace(/\/$/,"");return"input"===t?`${r}/input_schema`:`${r}/output_schema`})(e,"input"),this.init()}get dataTransferMode(){return this.theDataTransferModeToUse}get endpointUrl(){return this.theEndpointUrlToUse}get headers(){return this.theHeadersToUse}get id(){return this.__instanceId}get info(){return{id:"langserve-adapter",capabilities:{chat:!0,fileUpload:!1,textToSpeech:!1,speechToText:!1}}}get inputPreProcessor(){return this.__options.inputPreProcessor}get inputSchema(){return this.theInputSchemaToUse}get outputPreProcessor(){return this.__options.outputPreProcessor}get runnableName(){return this.theRunnableNameToUse}get useInputSchema(){return this.theUseInputSchemaOptionToUse}get inputSchemaUrl(){return this.theInputSchemaUrlToUse}async fetchSchema(e){try{const r=await fetch(e),s=await r.json();return"object"==typeof s&&s?s:void t.warn(`LangServe adapter is unable process schema loaded from: ${e}`)}catch(r){return void t.warn(`LangServe adapter is unable to fetch schema from: ${e}`)}}init(){!this.inputPreProcessor&&this.useInputSchema&&this.fetchSchema(this.inputSchemaUrl).then((e=>{this.theInputSchemaToUse=e}))}getDisplayableMessageFromAiOutput(e){if(this.outputPreProcessor)return this.outputPreProcessor(e);if("string"==typeof e)return e;const r=e;if("object"==typeof r&&r&&"string"==typeof r.content)return r.content;t.warn(`LangServe adapter is unable to process output returned from the endpoint:\n ${JSON.stringify(e)}`)}getRequestBody(e,r){if(this.inputPreProcessor){const t=this.inputPreProcessor(e,r);return JSON.stringify({input:t})}if(this.inputSchema){const r=((e,r,s,o)=>{if(!s||"object"!=typeof s.properties)return e;if("object"!=typeof s||!s)return t.warn(`LangServer adapter cannot process the input schema fetched for runnable "${o}". The user message will be sent to LangServe endpoint as is without transformations. To override this behavior, you can either set the "useInputSchema" option to false, or provide a custom input pre-processor via the "inputPreProcessor" option, or update your endpoint and input schema to have an object with a single string property or a string as input.`),e;if("string"===s.type)return e;if("object"===s.type){const r="object"==typeof s.properties&&s.properties?s.properties:{},o=Object.keys(r).filter((e=>e&&"string"==typeof s.properties[e].type)).map((e=>e));if(1===o.length)return{[o[0]]:e};t.warn('LangServer adapter cannot find a valid property to match to user input inside the "${runnableName}" input schema. The user message will be sent to LangServe endpoint as is without transformations. To override this behavior, you can either set the "useInputSchema" option to false, or provide a custom input pre-processor via the "inputPreProcessor" option, or update your endpoint and input schema to have an object with a single string property or a string accepted as part of input schema.')}})(e,0,this.inputSchema,this.runnableName);if(void 0!==r)return JSON.stringify({input:r})}return JSON.stringify({input:e})}}a.defaultDataTransferMode="stream";class i extends a{constructor(e){super(e)}async fetchText(e,t){const r=this.getRequestBody(e,t.conversationHistory),s=await fetch(this.endpointUrl,{method:"POST",headers:{...this.headers,"Content-Type":"application/json"},body:r});if(!s.ok)throw new Error(`LangServe runnable returned status code: ${s.status}`);const o=await s.json();if("object"!=typeof o||!o||void 0===o.output)throw new Error('Invalid response from LangServe runnable: Response is not an object or does not contain an "output" property');const n="object"==typeof o&&o?o.output:void 0;return this.getDisplayableMessageFromAiOutput(n)??""}streamText(e,r,s){throw new t.NluxUsageError({source:this.constructor.name,message:"Cannot stream text from the fetch adapter!"})}}const u=e=>{const r=/^event:\s+(?<event>[\w]+)((\r?)\n(\r?)data: (?<data>(.|\n)*))?/gm.exec(e);if(!r)return;const{event:s,data:o}=r.groups||{};if(s&&("data"===s||"end"===s))try{return{event:s,data:o?JSON.parse(o):void 0}}catch(e){return t.warn(`LangServe stream adapter failed to parse data for chunk event "${s}" | Data: ${o}`),{event:s,data:void 0}}},h=e=>{if(!e)return[];const t=/(((?<=^)|(?<=\n))event:\s+(\w+))/g,r=[];let s=t.exec(e);for(;s;)r.push(s.index),s=t.exec(e);const o=(t,s)=>{const o=r[s+1]||e.length;return e.substring(t,o)};try{return r.map(o).map(u).filter((e=>void 0!==e)).map((e=>e))}catch(e){return e instanceof Error?e:[]}},c=e=>"object"==typeof e&&null!==e&&e.message?.toLowerCase().includes("connection error")?"NX-NT-001":null;class p extends a{constructor(e){super(e)}async fetchText(e,r){throw new t.NluxUsageError({source:this.constructor.name,message:"Cannot fetch text using the stream adapter!"})}streamText(e,r,s){const o=this.getRequestBody(e,s.conversationHistory);fetch(this.endpointUrl,{method:"POST",headers:{...this.headers,"Content-Type":"application/json"},body:o}).then((async e=>{if(!e.ok)throw new t.NluxError({source:this.constructor.name,message:`LangServe runnable returned status code: ${e.status}`});if(!e.body)throw new t.NluxError({source:this.constructor.name,message:`LangServe runnable returned status code: ${e.status}`});const s=e.body.getReader(),o=new TextDecoder;let n=!1;for(;!n;){const{value:e,done:a}=await s.read();if(a){n=!0;continue}const i=o.decode(e),u=h(i);if(Array.isArray(u))for(const e of u){if("data"===e.event&&void 0!==e.data){const t=this.getDisplayableMessageFromAiOutput(e.data);"string"==typeof t&&t&&r.next(t)}if("end"===e.event){r.complete(),n=!0;break}}u instanceof Error&&(t.warn(u),r.error(u),n=!0)}})).catch((e=>{t.warn(e),r.error(new t.NluxUsageError({source:this.constructor.name,message:e.message,exceptionId:c(e)??void 0}))}))}}class d{constructor(e){e&&(this.theDataTransferMode=e.theDataTransferMode,this.theHeaders=e.theHeaders,this.theInputPreProcessor=e.theInputPreProcessor,this.theOutputPreProcessor=e.theOutputPreProcessor,this.theUrl=e.theUrl)}create(){if(!this.theUrl)throw new t.NluxUsageError({source:this.constructor.name,message:"Unable to create LangServe adapter. URL is missing. Make sure you are calling withUrl() before calling create()."});const e={url:this.theUrl,dataTransferMode:this.theDataTransferMode,headers:this.theHeaders,inputPreProcessor:this.theInputPreProcessor,outputPreProcessor:this.theOutputPreProcessor,useInputSchema:this.theUseInputSchema};return"stream"===s(e)?new p(e):new i(e)}withDataTransferMode(e){if(void 0!==this.theDataTransferMode)throw new t.NluxUsageError({source:this.constructor.name,message:"Cannot set the data loading mode more than once"});return this.theDataTransferMode=e,this}withHeaders(e){if(void 0!==this.theHeaders)throw new t.NluxUsageError({source:this.constructor.name,message:"Cannot set the headers option more than once"});return this.theHeaders=e,this}withInputPreProcessor(e){if(void 0!==this.theInputPreProcessor)throw new t.NluxUsageError({source:this.constructor.name,message:"Cannot set the input pre-processor option more than once"});return this.theInputPreProcessor=e,this}withInputSchema(e){if(void 0!==this.theUseInputSchema)throw new t.NluxUsageError({source:this.constructor.name,message:"Cannot set the input schema option more than once"});return this.theUseInputSchema=e,this}withOutputPreProcessor(e){if(void 0!==this.theOutputPreProcessor)throw new t.NluxUsageError({source:this.constructor.name,message:"Cannot set the output pre-processor option more than once"});return this.theOutputPreProcessor=e,this}withUrl(e){if(void 0!==this.theUrl)throw new t.NluxUsageError({source:this.constructor.name,message:"Cannot set the runnable URL option more than once"});return this.theUrl=e,this}}Object.defineProperty(e,"debug",{enumerable:!0,get:function(){return t.debug}}),e.createChatAdapter=()=>new d}));
